Authors' implementation of **Too Late to Train, Too Early To Use? A Study on Necessity and Viability of Low-Resource Bengali LLMs**

**The 31st International Conference on Computational Linguistics COLING 2025**
# BanglaBench
BanglaBench explores the necessity of Bengali-specific large language models (LLMs) by benchmarking open-weight and closed-source LLMs like LLaMA-3 and GPT-4 against fine-tuned encoder-decoder models on diverse Bengali NLP tasks, including translation, summarization, and question-answering. The findings highlight key challenges such as inefficient tokenization of Bengali script and biases in machine-translated datasets, emphasizing the urgent need for a dedicated Bengali LLM backed by high-quality pretraining and instruction-tuning datasets.


